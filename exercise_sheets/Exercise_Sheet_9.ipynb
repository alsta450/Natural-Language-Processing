{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## Exercise Sheet 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for all exercises\n",
    "import nltk\n",
    "from nltk import grammar, parse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Take the following grammar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "%start S\n",
    "S                    -> NP[AGR=?n] VP[AGR=?n]\n",
    "NP[AGR=?n]           -> PropN[AGR=?n]\n",
    "VP[TENSE=?t, AGR=?n] -> Cop[TENSE=?t, AGR=?n] Adj\n",
    "\n",
    "\n",
    "Cop[TENSE=pres,  AGR=[NUM=sg, PER=3]] -> 'is'\n",
    "PropN[AGR=[NUM=sg, PER=3]]            -> 'Kim'\n",
    "Adj                                   -> 'happy'\n",
    "\"\"\"\n",
    "gr = grammar.FeatureGrammar.fromstring(g)\n",
    "\n",
    "def parse_sent(sent, gr):\n",
    "    tokens = sent.split()\n",
    "    parser = parse.FeatureEarleyChartParser(gr)\n",
    "    trees = parser.parse(tokens)\n",
    "    for tree in trees: print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as starting point to correctly parse word sequences like \"I am happy\" and \"she is happy\" but not \" * you is happy\" or \" * they am happy\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"I am happy\"\n",
    "sent2 = \"she is happy\"\n",
    "sent3 = \"you is happy\"\n",
    "sent4 = \"they am happy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "Develop a variant of the following grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "% start S\n",
    "# ###################\n",
    "# Grammar Productions\n",
    "# ###################\n",
    "# S expansion productions\n",
    "S -> NP[NUM=?n] VP[NUM=?n]\n",
    "# NP expansion productions\n",
    "NP[NUM=?n] -> N[NUM=?n]\n",
    "NP[NUM=?n] -> PropN[NUM=?n]\n",
    "NP[NUM=?n] -> Det[NUM=?n] N[NUM=?n]\n",
    "NP[NUM=pl] -> N[NUM=pl]\n",
    "# VP expansion productions\n",
    "VP[TENSE=?t, NUM=?n] -> IV[TENSE=?t, NUM=?n]\n",
    "VP[TENSE=?t, NUM=?n] -> TV[TENSE=?t, NUM=?n] NP\n",
    "# ###################\n",
    "# Lexical Productions\n",
    "# ###################\n",
    "Det[NUM=sg] -> 'this' | 'every'\n",
    "Det[NUM=pl] -> 'these' | 'all'\n",
    "Det -> 'the' | 'some' | 'several'\n",
    "PropN[NUM=sg]-> 'Kim' | 'Jody'\n",
    "N[NUM=sg] -> 'dog' | 'girl' | 'car' | 'child'\n",
    "N[NUM=pl] -> 'dogs' | 'girls' | 'cars' | 'children'\n",
    "IV[TENSE=pres,  NUM=sg] -> 'disappears' | 'walks'\n",
    "TV[TENSE=pres, NUM=sg] -> 'sees' | 'likes'\n",
    "IV[TENSE=pres,  NUM=pl] -> 'disappear' | 'walk'\n",
    "TV[TENSE=pres, NUM=pl] -> 'see' | 'like'\n",
    "IV[TENSE=past] -> 'disappeared' | 'walked'\n",
    "TV[TENSE=past] -> 'saw' | 'liked'\n",
    "\"\"\"\n",
    "gr = grammar.FeatureGrammar.fromstring(g)\n",
    "\n",
    "def parse_sent(sent, gr):\n",
    "    tokens = sent.split()\n",
    "    parser = parse.FeatureEarleyChartParser(gr)\n",
    "    trees = parser.parse(tokens)\n",
    "    for tree in trees: print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "that uses a feature `COUNT` to make the distinctions shown below:\n",
    "\n",
    "(1a) the boy sings\n",
    "\n",
    "(1b) * boy sings\n",
    "\n",
    "(2a) the boys sing\n",
    "\n",
    "(2b) boys sing\n",
    "\n",
    "(3a) the water is precious\n",
    "\n",
    "(3b) water is precious"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"the boy sings\"\n",
    "sent2 = \"boy sings\"\n",
    "sent3 = \"the boys sing\"\n",
    "sent4 = \"boys sing\"\n",
    "sent5 = \"the water is precious\"\n",
    "sent6 = \"water is precious\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "Extend the German grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "% start S\n",
    "# Grammar Productions\n",
    " S -> NP[CASE=nom, AGR=?a] VP[AGR=?a]\n",
    " NP[CASE=?c, AGR=?a] -> PRO[CASE=?c, AGR=?a]\n",
    " NP[CASE=?c, AGR=?a] -> Det[CASE=?c, AGR=?a] N[CASE=?c, AGR=?a]\n",
    " VP[AGR=?a] -> IV[AGR=?a]\n",
    " VP[AGR=?a] -> TV[OBJCASE=?c, AGR=?a] NP[CASE=?c]\n",
    " # Lexical Productions\n",
    " # Singular determiners\n",
    " # masc\n",
    " Det[CASE=nom, AGR=[GND=masc,PER=3,NUM=sg]] -> 'der'\n",
    " Det[CASE=dat, AGR=[GND=masc,PER=3,NUM=sg]] -> 'dem'\n",
    " Det[CASE=acc, AGR=[GND=masc,PER=3,NUM=sg]] -> 'den'\n",
    " # fem\n",
    " Det[CASE=nom, AGR=[GND=fem,PER=3,NUM=sg]] -> 'die'\n",
    " Det[CASE=dat, AGR=[GND=fem,PER=3,NUM=sg]] -> 'der'\n",
    " Det[CASE=acc, AGR=[GND=fem,PER=3,NUM=sg]] -> 'die'\n",
    " # Plural determiners\n",
    " Det[CASE=nom, AGR=[PER=3,NUM=pl]] -> 'die'\n",
    " Det[CASE=dat, AGR=[PER=3,NUM=pl]] -> 'den'\n",
    " Det[CASE=acc, AGR=[PER=3,NUM=pl]] -> 'die'\n",
    " # Nouns\n",
    " N[AGR=[GND=masc,PER=3,NUM=sg]] -> 'Hund'\n",
    " N[CASE=nom, AGR=[GND=masc,PER=3,NUM=pl]] -> 'Hunde'\n",
    " N[CASE=dat, AGR=[GND=masc,PER=3,NUM=pl]] -> 'Hunden'\n",
    " N[CASE=acc, AGR=[GND=masc,PER=3,NUM=pl]] -> 'Hunde'\n",
    " N[AGR=[GND=fem,PER=3,NUM=sg]] -> 'Katze'\n",
    " N[AGR=[GND=fem,PER=3,NUM=pl]] -> 'Katzen'\n",
    " # Pronouns\n",
    " PRO[CASE=nom, AGR=[PER=1,NUM=sg]] -> 'ich'\n",
    " PRO[CASE=acc, AGR=[PER=1,NUM=sg]] -> 'mich'\n",
    " PRO[CASE=dat, AGR=[PER=1,NUM=sg]] -> 'mir'\n",
    " PRO[CASE=nom, AGR=[PER=2,NUM=sg]] -> 'du'\n",
    " PRO[CASE=nom, AGR=[PER=3,NUM=sg]] -> 'er' | 'sie' | 'es'\n",
    " PRO[CASE=nom, AGR=[PER=1,NUM=pl]] -> 'wir'\n",
    " PRO[CASE=acc, AGR=[PER=1,NUM=pl]] -> 'uns'\n",
    " PRO[CASE=dat, AGR=[PER=1,NUM=pl]] -> 'uns'\n",
    " PRO[CASE=nom, AGR=[PER=2,NUM=pl]] -> 'ihr'\n",
    " PRO[CASE=nom, AGR=[PER=3,NUM=pl]] -> 'sie'\n",
    " # Verbs\n",
    " IV[AGR=[NUM=sg,PER=1]] -> 'komme'\n",
    " IV[AGR=[NUM=sg,PER=2]] -> 'kommst'\n",
    " IV[AGR=[NUM=sg,PER=3]] -> 'kommt'\n",
    " IV[AGR=[NUM=pl, PER=1]] -> 'kommen'\n",
    " IV[AGR=[NUM=pl, PER=2]] -> 'kommt'\n",
    " IV[AGR=[NUM=pl, PER=3]] -> 'kommen'\n",
    " TV[OBJCASE=acc, AGR=[NUM=sg,PER=1]] -> 'sehe' | 'mag'\n",
    " TV[OBJCASE=acc, AGR=[NUM=sg,PER=2]] -> 'siehst' | 'magst'\n",
    " TV[OBJCASE=acc, AGR=[NUM=sg,PER=3]] -> 'sieht' | 'mag'\n",
    " TV[OBJCASE=dat, AGR=[NUM=sg,PER=1]] -> 'folge' | 'helfe'\n",
    " TV[OBJCASE=dat, AGR=[NUM=sg,PER=2]] -> 'folgst' | 'hilfst'\n",
    " TV[OBJCASE=dat, AGR=[NUM=sg,PER=3]] -> 'folgt' | 'hilft'\n",
    " TV[OBJCASE=acc, AGR=[NUM=pl,PER=1]] -> 'sehen' | 'moegen'\n",
    " TV[OBJCASE=acc, AGR=[NUM=pl,PER=2]] -> 'sieht' | 'moegt'\n",
    " TV[OBJCASE=acc, AGR=[NUM=pl,PER=3]] -> 'sehen' | 'moegen'\n",
    " TV[OBJCASE=dat, AGR=[NUM=pl,PER=1]] -> 'folgen' | 'helfen'\n",
    " TV[OBJCASE=dat, AGR=[NUM=pl,PER=2]] -> 'folgt' | 'helft'\n",
    " TV[OBJCASE=dat, AGR=[NUM=pl,PER=3]] -> 'folgen' | 'helfen'\n",
    "\n",
    "\"\"\"\n",
    "gr = grammar.FeatureGrammar.fromstring(g)\n",
    "\n",
    "def parse_sent(sent, gr):\n",
    "    tokens = sent.split()\n",
    "    parser = parse.FeatureEarleyChartParser(gr)\n",
    "    trees = parser.parse(tokens)\n",
    "    for tree in trees: print(tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so that it can handle so-called verb-second structures like \"heute sieht der Hund die Katze\" by using a slash category `S/TV` for the missing transitive verb in \"der Hund die Katze\". Use the following test sentences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent1 = \"heute sieht der Hund die Katze\"\n",
    "sent2 = \"heute sehe der Hund die Katze\"\n",
    "sent3 = \"heute sieht der Hund die Katzen\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Consider the patterns of grammaticality for the verbs \"loaded\", \"filled\", and \"dumped\" below. Write grammar productions to handle such data:\n",
    "\n",
    "(1a) the farmer loaded the cart with sand\n",
    "\n",
    "(1b) the farmer loaded sand into the cart\n",
    "\n",
    "(2a) the farmer filled the cart with sand\n",
    "\n",
    "(2b) * the farmer filled sand into the cart\n",
    "\n",
    "(3a) * the farmer dumped the cart with sand\n",
    "\n",
    "(3b) the farmer dumped sand into the cart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g = \"\"\"\n",
    "% start S\n",
    "# Grammar Productions\n",
    "\n",
    "\"\"\"\n",
    "#gr = grammar.FeatureGrammar.fromstring(g)\n",
    "\n",
    "def parse_sent(sent, gr):\n",
    "    tokens = sent.split()\n",
    "    parser = parse.FeatureEarleyChartParser(gr)\n",
    "    trees = parser.parse(tokens)\n",
    "    for tree in trees: print(tree)\n",
    "sent1 = \"the farmer loaded the cart with sand\"\n",
    "sent2 = \"the farmer loaded sand into the cart\"\n",
    "sent3 = \"the farmer filled the cart with sand\"\n",
    "sent4 = \"the farmer filled sand into the cart\"\n",
    "sent5 = \"the farmer dumped the cart with sand\"\n",
    "sent6 = \"the farmer dumped sand into the cart\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "Consider the following feature structures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "fs1 = nltk.FeatStruct(\"[A = ?x, B= [C = ?x]]\")\n",
    "fs2 = nltk.FeatStruct(\"[B = [D = d]]\")\n",
    "fs3 = nltk.FeatStruct(\"[B = [C = d]]\")\n",
    "fs4 = nltk.FeatStruct(\"[A = (1)[B = b], C->(1)]\")\n",
    "fs5 = nltk.FeatStruct(\"[A = (1)[D = ?x], C = [E -> (1), F = ?x] ]\")\n",
    "fs6 = nltk.FeatStruct(\"[A = [D = d]]\")\n",
    "fs7 = nltk.FeatStruct(\"[A = [D = d], C = [F = [D = d]]]\")\n",
    "fs8 = nltk.FeatStruct(\"[A = (1)[D = ?x, G = ?x], C = [B = ?x, E -> (1)] ]\")\n",
    "fs9 = nltk.FeatStruct(\"[A = [B = b], C = [E = [G = e]]]\")\n",
    "fs10 = nltk.FeatStruct(\"[A = (1)[B = b], C -> (1)]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the result of the following unifications? \n",
    "\n",
    "1. `fs1` and `fs2`,  \n",
    "2. `fs1` and `fs3`,  \n",
    "3. `fs4` and `fs5`,  \n",
    "4. `fs5` and `fs6`,  \n",
    "5. `fs5` and `fs7`,  \n",
    "6. `fs8` and `fs9`,  \n",
    "7. `fs8` and `fs10`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
