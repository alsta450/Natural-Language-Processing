{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Natural Language Processing\n",
    "\n",
    "## Exercise Sheet 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports for all exercises\n",
    "import nltk\n",
    "import random\n",
    "from nltk.classify import apply_features\n",
    "from nltk.corpus import names,brown,ppattach,movie_reviews\n",
    "import functools\n",
    "import inflect\n",
    "from string import ascii_lowercase\n",
    "import statistics\n",
    "from pickle import load"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 1\n",
    "\n",
    "Write a name gender classifier using the Names Corpus, the `apply_features` function, shuffling, and a test set of 500 instances. Use the following features:\n",
    "\n",
    "a) first letter;  \n",
    "b) last letter;  \n",
    "c) last two letters;  \n",
    "d) length;  \n",
    "e) for each letter one feature, which is true if the name contains the letter.\n",
    "\n",
    "Use the `NaiveBayesClassifier`, calculate the accuracy, and display the 10 most informative features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions \n",
    "\n",
    "# if the position is negative return the last n chars else return the first n chars\n",
    "def gender_features(word,position):\n",
    "    if position < 0:\n",
    "        pos = 'last_' + inflect.engine().number_to_words(abs(position)) + '_letters'\n",
    "        return {pos : word[position:]}\n",
    "    else:\n",
    "        pos ='first_' + inflect.engine().number_to_words(abs(position)) + '_letters'\n",
    "        return {pos : word[:position]}\n",
    "\n",
    "#return the length of the word\n",
    "def length_features(word,position):\n",
    "    return {'length':len(word)}\n",
    "\n",
    "#return true if letter in word else return false\n",
    "def contains_letter(word,position):\n",
    "    if position in word.lower():\n",
    "        return {'contains ' + position : True}\n",
    "    else:\n",
    "        return {'contains ' + position : False}\n",
    "\n",
    "# takes a position (or char) and a function \n",
    "# first create labeled naems, shuffle them, split them in train and test set according to a function which is given as argument, \n",
    "# and train the Bayes classifier on the train set\n",
    "# show most informative informations and the accuracy\n",
    "def specific_letter(position,func):\n",
    "    labeled_names = ([(name, 'male') for name in names.words('male.txt')] +\n",
    "        [(name, 'female') for name in names.words('female.txt')])\n",
    "    random.shuffle(labeled_names)\n",
    "    train_set = apply_features(functools.partial(func, position=position), labeled_names[500:])\n",
    "    test_set = apply_features(functools.partial(func, position=position), labeled_names[:500])\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "    print(classifier.show_most_informative_features(10))\n",
    "    print(nltk.classify.accuracy(classifier, test_set))\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'first_one_letters': 'F'}, 'female'), ({'first_one_letters': 'F'}, 'female'), ...]\n",
      "Most Informative Features\n",
      "       first_one_letters = 'W'              male : female =      4.7 : 1.0\n",
      "       first_one_letters = 'Q'              male : female =      2.7 : 1.0\n",
      "       first_one_letters = 'U'              male : female =      2.6 : 1.0\n",
      "       first_one_letters = 'K'            female : male   =      2.3 : 1.0\n",
      "       first_one_letters = 'X'              male : female =      2.3 : 1.0\n",
      "       first_one_letters = 'H'              male : female =      2.3 : 1.0\n",
      "       first_one_letters = 'Z'              male : female =      1.7 : 1.0\n",
      "       first_one_letters = 'L'            female : male   =      1.7 : 1.0\n",
      "       first_one_letters = 'C'            female : male   =      1.7 : 1.0\n",
      "       first_one_letters = 'T'              male : female =      1.6 : 1.0\n",
      "None\n",
      "0.662\n"
     ]
    }
   ],
   "source": [
    "#a)\n",
    "specific_letter(1,gender_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'last_one_letters': 'r'}, 'male'), ({'last_one_letters': 'e'}, 'male'), ...]\n",
      "Most Informative Features\n",
      "        last_one_letters = 'a'            female : male   =     35.2 : 1.0\n",
      "        last_one_letters = 'k'              male : female =     30.9 : 1.0\n",
      "        last_one_letters = 'v'              male : female =     18.7 : 1.0\n",
      "        last_one_letters = 'f'              male : female =     16.0 : 1.0\n",
      "        last_one_letters = 'p'              male : female =     11.9 : 1.0\n",
      "        last_one_letters = 'd'              male : female =     10.1 : 1.0\n",
      "        last_one_letters = 'm'              male : female =      8.3 : 1.0\n",
      "        last_one_letters = 'w'              male : female =      8.0 : 1.0\n",
      "        last_one_letters = 'o'              male : female =      8.0 : 1.0\n",
      "        last_one_letters = 'r'              male : female =      6.8 : 1.0\n",
      "None\n",
      "0.742\n"
     ]
    }
   ],
   "source": [
    "#b)\n",
    "specific_letter(-1,gender_features)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[({'last_two_letters': 'ey'}, 'female'), ({'last_two_letters': 'rl'}, 'female'), ...]\n",
      "Most Informative Features\n",
      "        last_two_letters = 'na'           female : male   =    101.3 : 1.0\n",
      "        last_two_letters = 'la'           female : male   =     76.4 : 1.0\n",
      "        last_two_letters = 'ia'           female : male   =     41.1 : 1.0\n",
      "        last_two_letters = 'sa'           female : male   =     34.9 : 1.0\n",
      "        last_two_letters = 'rd'             male : female =     32.4 : 1.0\n",
      "        last_two_letters = 'ta'           female : male   =     32.2 : 1.0\n",
      "        last_two_letters = 'us'             male : female =     26.7 : 1.0\n",
      "        last_two_letters = 'ra'           female : male   =     26.4 : 1.0\n",
      "        last_two_letters = 'do'             male : female =     24.8 : 1.0\n",
      "        last_two_letters = 'rt'             male : female =     22.9 : 1.0\n",
      "None\n",
      "0.796\n"
     ]
    }
   ],
   "source": [
    "#c)\n",
    "specific_letter(-2,gender_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "                  length = 2                male : female =      2.1 : 1.0\n",
      "                  length = 3                male : female =      2.0 : 1.0\n",
      "                  length = 15               male : female =      1.7 : 1.0\n",
      "                  length = 10             female : male   =      1.5 : 1.0\n",
      "                  length = 9              female : male   =      1.3 : 1.0\n",
      "                  length = 4                male : female =      1.2 : 1.0\n",
      "                  length = 11             female : male   =      1.1 : 1.0\n",
      "                  length = 7              female : male   =      1.1 : 1.0\n",
      "                  length = 12             female : male   =      1.1 : 1.0\n",
      "                  length = 5              female : male   =      1.1 : 1.0\n",
      "None\n",
      "0.654\n"
     ]
    }
   ],
   "source": [
    "#d)\n",
    "specific_letter(0,length_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Most Informative Features\n",
      "              contains a = False            male : female =      1.6 : 1.0\n",
      "              contains a = True           female : male   =      1.4 : 1.0\n",
      "None\n",
      "0.61\n",
      "Most Informative Features\n",
      "              contains b = True             male : female =      1.2 : 1.0\n",
      "              contains b = False          female : male   =      1.0 : 1.0\n",
      "None\n",
      "0.63\n",
      "Most Informative Features\n",
      "              contains c = True             male : female =      1.0 : 1.0\n",
      "              contains c = False          female : male   =      1.0 : 1.0\n",
      "None\n",
      "0.574\n",
      "Most Informative Features\n",
      "              contains d = True             male : female =      1.2 : 1.0\n",
      "              contains d = False          female : male   =      1.1 : 1.0\n",
      "None\n",
      "0.636\n",
      "Most Informative Features\n",
      "              contains e = False            male : female =      1.2 : 1.0\n",
      "              contains e = True           female : male   =      1.1 : 1.0\n",
      "None\n",
      "0.6\n",
      "Most Informative Features\n",
      "              contains f = True             male : female =      1.8 : 1.0\n",
      "              contains f = False          female : male   =      1.0 : 1.0\n",
      "None\n",
      "0.612\n",
      "Most Informative Features\n",
      "              contains g = True             male : female =      1.4 : 1.0\n",
      "              contains g = False          female : male   =      1.0 : 1.0\n",
      "None\n",
      "0.618\n",
      "Most Informative Features\n",
      "              contains h = True             male : female =      1.4 : 1.0\n",
      "              contains h = False          female : male   =      1.1 : 1.0\n",
      "None\n",
      "0.654\n",
      "Most Informative Features\n",
      "              contains i = True           female : male   =      1.4 : 1.0\n",
      "              contains i = False            male : female =      1.3 : 1.0\n",
      "None\n",
      "0.682\n",
      "Most Informative Features\n",
      "              contains j = True           female : male   =      1.2 : 1.0\n",
      "              contains j = False            male : female =      1.0 : 1.0\n",
      "None\n",
      "0.618\n",
      "Most Informative Features\n",
      "              contains k = True             male : female =      1.1 : 1.0\n",
      "              contains k = False          female : male   =      1.0 : 1.0\n",
      "None\n",
      "0.612\n",
      "Most Informative Features\n",
      "              contains l = True           female : male   =      1.3 : 1.0\n",
      "              contains l = False            male : female =      1.2 : 1.0\n",
      "None\n",
      "0.628\n",
      "Most Informative Features\n",
      "              contains m = True             male : female =      1.1 : 1.0\n",
      "              contains m = False          female : male   =      1.0 : 1.0\n",
      "None\n",
      "0.642\n",
      "Most Informative Features\n",
      "              contains n = True           female : male   =      1.2 : 1.0\n",
      "              contains n = False            male : female =      1.1 : 1.0\n",
      "None\n",
      "0.634\n",
      "Most Informative Features\n",
      "              contains o = True             male : female =      1.5 : 1.0\n",
      "              contains o = False          female : male   =      1.2 : 1.0\n",
      "None\n",
      "0.626\n",
      "Most Informative Features\n",
      "              contains p = True             male : female =      1.8 : 1.0\n",
      "              contains p = False          female : male   =      1.0 : 1.0\n",
      "None\n",
      "0.622\n",
      "Most Informative Features\n",
      "              contains q = True           female : male   =      1.1 : 1.0\n",
      "              contains q = False            male : female =      1.0 : 1.0\n",
      "None\n",
      "0.638\n",
      "Most Informative Features\n",
      "              contains r = True             male : female =      1.2 : 1.0\n",
      "              contains r = False          female : male   =      1.1 : 1.0\n",
      "None\n",
      "0.622\n",
      "Most Informative Features\n",
      "              contains s = True             male : female =      1.2 : 1.0\n",
      "              contains s = False          female : male   =      1.1 : 1.0\n",
      "None\n",
      "0.644\n",
      "Most Informative Features\n",
      "              contains t = True             male : female =      1.2 : 1.0\n",
      "              contains t = False          female : male   =      1.0 : 1.0\n",
      "None\n",
      "0.636\n",
      "Most Informative Features\n",
      "              contains u = True             male : female =      1.8 : 1.0\n",
      "              contains u = False          female : male   =      1.1 : 1.0\n",
      "None\n",
      "0.622\n",
      "Most Informative Features\n",
      "              contains v = True             male : female =      1.4 : 1.0\n",
      "              contains v = False          female : male   =      1.0 : 1.0\n",
      "None\n",
      "0.638\n",
      "Most Informative Features\n",
      "              contains w = True             male : female =      4.3 : 1.0\n",
      "              contains w = False          female : male   =      1.1 : 1.0\n",
      "None\n",
      "0.676\n",
      "Most Informative Features\n",
      "              contains x = True             male : female =      1.4 : 1.0\n",
      "              contains x = False          female : male   =      1.0 : 1.0\n",
      "None\n",
      "0.622\n",
      "Most Informative Features\n",
      "              contains y = True           female : male   =      1.1 : 1.0\n",
      "              contains y = False            male : female =      1.0 : 1.0\n",
      "None\n",
      "0.632\n",
      "Most Informative Features\n",
      "              contains z = True             male : female =      1.5 : 1.0\n",
      "              contains z = False          female : male   =      1.0 : 1.0\n",
      "None\n",
      "0.646\n"
     ]
    }
   ],
   "source": [
    "#e)\n",
    "for char in ascii_lowercase:\n",
    "    specific_letter(char,contains_letter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 2\n",
    "\n",
    "The Senseval 2 Corpus contains data intended to train word-sense disambiguation classifiers. Using this dataset, build a `NaiveBayesClassifier` that predicts the correct sense tag for a given instance for the word \"hard\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SensevalInstance(word='hard-a', position=20, context=[('``', '``'), ('he', 'PRP'), ('may', 'MD'), ('lose', 'VB'), ('all', 'DT'), ('popular', 'JJ'), ('support', 'NN'), (',', ','), ('but', 'CC'), ('someone', 'NN'), ('has', 'VBZ'), ('to', 'TO'), ('kill', 'VB'), ('him', 'PRP'), ('to', 'TO'), ('defeat', 'VB'), ('him', 'PRP'), ('and', 'CC'), ('that', 'DT'), (\"'s\", 'VBZ'), ('hard', 'JJ'), ('to', 'TO'), ('do', 'VB'), ('.', '.'), (\"''\", \"''\")], senses=('HARD1',)), SensevalInstance(word='hard-a', position=10, context=[('clever', 'NNP'), ('white', 'NNP'), ('house', 'NNP'), ('``', '``'), ('spin', 'VB'), ('doctors', 'NNS'), (\"''\", \"''\"), ('are', 'VBP'), ('having', 'VBG'), ('a', 'DT'), ('hard', 'JJ'), ('time', 'NN'), ('helping', 'VBG'), ('president', 'NNP'), ('bush', 'NNP'), ('explain', 'VB'), ('away', 'RB'), ('the', 'DT'), ('economic', 'JJ'), ('bashing', 'NN'), ('that', 'IN'), ('low-and', 'JJ'), ('middle-income', 'JJ'), ('workers', 'NNS'), ('are', 'VBP'), ('taking', 'VBG'), ('these', 'DT'), ('days', 'NNS'), ('.', '.')], senses=('HARD1',)), ...]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import senseval\n",
    "instances = senseval.instances()\n",
    "instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import senseval\n",
    "instances = senseval.instances('hard.pos')\n",
    "labeled_instances = [(inst, inst.senses) for inst in instances] \n",
    "size = int(len(labeled_instances) * 0.1)\n",
    "random.shuffle(labeled_instances)\n",
    "train_set = apply_features(features, labeled_instances[size:])\n",
    "test_set = apply_features(features, labeled_instances[:size])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the preceding and following word as features. They can be calculated by retrieving the position of the word \"hard\" as `p=inst.position` and then accessing `inst.context[p-1]` and `inst.context[p+1]`.\n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the individual accuracies. Finally, print the average accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 3\n",
    "\n",
    "The synonyms \"strong\" and \"powerful\" pattern differently. Use the tagged Brown corpus with the universal tagset to first list the nouns which follow \"strong\" vs. \"powerful\". Write for this a function `next_noun(word, tagged_text)` which returns the list of nouns that follow `word` in the `tagged_text`. Build then a `NaiveBayesClassifier` that predicts when each word should be used by using the function `apply_features` and the following noun as single feature.\n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the individual accuracies. Finally, print the average accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the next word after a given word if it's a noun and return a list of all found words\n",
    "def next_noun(word, tagged_text):\n",
    "    ret_ = []\n",
    "    for i in range (0, len(tagged_text)-1):\n",
    "        if tagged_text[i][0].lower() == word:\n",
    "            if tagged_text[i+1][1] == 'NOUN':\n",
    "                ret_.append((tagged_text[i+1][0], word))\n",
    "    return ret_\n",
    "\n",
    "noun_list_strong = next_noun('strong', brown.tagged_words(tagset='universal'))\n",
    "noun_list_powerful = next_noun('powerful', brown.tagged_words(tagset='universal'))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_function(word):\n",
    "    return {'word' : word}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7857142857142857\n",
      "Accuracy: 0.8571428571428571\n",
      "Accuracy: 0.6428571428571429\n",
      "Accuracy: 0.7142857142857143\n",
      "Accuracy: 0.7857142857142857\n",
      "Accuracy: 0.7857142857142857\n",
      "Accuracy: 0.5714285714285714\n",
      "Accuracy: 0.6428571428571429\n",
      "Accuracy: 0.7857142857142857\n",
      "Accuracy: 0.7857142857142857\n",
      "Overall mean: 0.7357142857142858\n"
     ]
    }
   ],
   "source": [
    "# iterate 10 times: split labeled list in test and trainset and train NBC on the test-set\n",
    "# print accuracy\n",
    "# print average accuracy after the 10 iterations\n",
    "list_combined = noun_list_strong + noun_list_powerful\n",
    "overall_acc_list = []\n",
    "for i in range (0,10):\n",
    "    random.shuffle(list_combined)\n",
    "    train_set = apply_features(map_function,list_combined[int(len(list_combined)*0.9):])\n",
    "    test_set = apply_features(map_function,list_combined[:int(len(list_combined)*0.1)])\n",
    "    classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "    acc = nltk.classify.accuracy(classifier, test_set)\n",
    "    overall_acc_list.append(acc)\n",
    "    print(\"Accuracy: \" + str(acc))\n",
    "\n",
    "print(\"Overall mean: \" + str(statistics.mean(overall_acc_list)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 4\n",
    "\n",
    "Based on the Movie Reviews document classifier discussed in this chapter, build a new `NaiveBayesClassifier`. Tag first the Movie Reviews Corpus using the combined tagger from the previous chapter stored in `t2.pkl`. Filter the tagged words to contain only words for the tags `['JJ', 'JJR', 'JJS', 'RB', 'NN', 'NNS', 'VB', 'VBN', 'VBG', 'VBZ', 'VBD', 'QL']` as well as only alphabetic tokens with at least three characters. Convert the words to lowercase. Use the most common 5000 words as `word_features` in the function `document_features`. \n",
    "\n",
    "Run 10 iterations by reshuffling the instances and printing the accuracy and 5 most informative features for each iteration. Finally, print the average accuracy.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise 5\n",
    "\n",
    "The PP Attachment Corpus is a corpus describing prepositional phrase attachment decisions. Each instance in the training corpus is encoded as a `PPAttachment` object:\n",
    "\n",
    "    from nltk.corpus import ppattach\n",
    "    ppattach.attachments('training')\n",
    "    \n",
    "        [PPAttachment(sent='0', verb='join', noun1='board',\n",
    "            prep='as', noun2='director', attachment='V'),\n",
    "        PPAttachment(sent='1', verb='is', noun1='chairman',\n",
    "            prep='of', noun2='N.V.', attachment='N'),\n",
    "        ...]\n",
    "\n",
    "    inst = ppattach.attachments('training')[1]\n",
    "    (inst.noun1, inst.prep, inst.noun2)\n",
    "    \n",
    "        ('chairman', 'of', 'N.V.')\n",
    "\n",
    "In the same way, `ppattach.attachments('test')` accesses the test instances. Select only the instances where `inst.attachment` is `'N'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nattach = [inst for inst in ppattach.attachments('training')\n",
    "               if inst.attachment == 'N']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using this sub-corpus, build a `NaiveBayesClassifier` that attempts to predict which preposition is used to connect a given pair of nouns. For example, given the pair of nouns \"team\" and \"researchers\", the classifier should predict the preposition \"of\". \n",
    "\n",
    "Write for this purpose a function `prepare_featuresets(subcorpus)`, where `subcorpus` is either the string \"training\" or \"test\" to return the training set or the test set. \n",
    "\n",
    "Print the achieved accuracy as well as the result of `classifier.classify({ 'noun1': 'team', 'noun2': 'researchers' })`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5690032858707558\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'of'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def extract(attachment):\n",
    "    return ({'noun1':attachment.noun1, 'noun2': attachment.noun2},attachment.prep)\n",
    "\n",
    "def prepare_featuresets(subcorpus):\n",
    "    nattach = [inst for inst in ppattach.attachments(subcorpus)\n",
    "               if inst.attachment == 'N']\n",
    "    set_ = apply_features(extract,nattach)\n",
    "    return set_\n",
    "\n",
    "train_set = prepare_featuresets('training')\n",
    "test_set = prepare_featuresets('test')\n",
    "classifier = nltk.NaiveBayesClassifier.train(train_set)\n",
    "\n",
    "print(nltk.classify.accuracy(classifier, test_set))\n",
    "classifier.classify({ 'noun1': 'team', 'noun2': 'researchers' })\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7691dc7e968cae2c1305b7cd748cf3c51f27e2f981106cfee5b02ab727978e13"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
